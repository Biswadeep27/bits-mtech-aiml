{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.arange(1, 101, step=0.1)\n",
    "y = [x + 10 for x in X]\n",
    "\n",
    "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 22:09:22.880045: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 14ms/step - loss: 13.4682 - mean_absolute_error: 13.4682\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 4.6444 - mean_absolute_error: 4.6444\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 8.4674 - mean_absolute_error: 8.4674\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 8.4158 - mean_absolute_error: 8.4158\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 4.7097 - mean_absolute_error: 4.7097\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 7.3260 - mean_absolute_error: 7.3260\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.2205 - mean_absolute_error: 3.2205\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 5.0367 - mean_absolute_error: 5.0367\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 7.4772 - mean_absolute_error: 7.4772\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 8.3898 - mean_absolute_error: 8.3898\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 3.4847 - mean_absolute_error: 3.4847\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 3.2023 - mean_absolute_error: 3.2023\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.8278 - mean_absolute_error: 3.8278\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.6037 - mean_absolute_error: 1.6037\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.7497 - mean_absolute_error: 3.7497\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.1872 - mean_absolute_error: 2.1872\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.1631 - mean_absolute_error: 3.1631\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.9326 - mean_absolute_error: 2.9326\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 4.0002 - mean_absolute_error: 4.0002\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.0886 - mean_absolute_error: 2.0886\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.9140 - mean_absolute_error: 2.9140\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.9738 - mean_absolute_error: 1.9738\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 2.5477 - mean_absolute_error: 2.5477\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.2601 - mean_absolute_error: 2.2601\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 3.4006 - mean_absolute_error: 3.4006\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 3.6518 - mean_absolute_error: 3.6518\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.9700 - mean_absolute_error: 2.9700\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.4773 - mean_absolute_error: 2.4773\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.9312 - mean_absolute_error: 1.9312\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.6016 - mean_absolute_error: 2.6016\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.8487 - mean_absolute_error: 2.8487\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.1444 - mean_absolute_error: 2.1444\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.7764 - mean_absolute_error: 2.7764\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.0011 - mean_absolute_error: 3.0011\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.7025 - mean_absolute_error: 2.7025\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.3327 - mean_absolute_error: 2.3327\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.1379 - mean_absolute_error: 2.1379\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.3683 - mean_absolute_error: 3.3683\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.6628 - mean_absolute_error: 1.6628\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.9112 - mean_absolute_error: 3.9112\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.5788 - mean_absolute_error: 2.5788\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.8548 - mean_absolute_error: 2.8548\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.5564 - mean_absolute_error: 1.5564\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.6963 - mean_absolute_error: 2.6963\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.3594 - mean_absolute_error: 3.3594\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.7464 - mean_absolute_error: 1.7464\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.3718 - mean_absolute_error: 2.3718\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 5.4604 - mean_absolute_error: 5.4604\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.9587 - mean_absolute_error: 2.9587\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.3518 - mean_absolute_error: 3.3518\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.7241 - mean_absolute_error: 1.7241\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.8311 - mean_absolute_error: 1.8311\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.3353 - mean_absolute_error: 1.3353\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.8314 - mean_absolute_error: 3.8314\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.4654 - mean_absolute_error: 1.4654\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.6665 - mean_absolute_error: 1.6665\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.6775 - mean_absolute_error: 2.6775\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.9483 - mean_absolute_error: 1.9483\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 4.1419 - mean_absolute_error: 4.1419\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.3901 - mean_absolute_error: 1.3901\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.2092 - mean_absolute_error: 1.2092\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.2498 - mean_absolute_error: 2.2498\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.0330 - mean_absolute_error: 2.0330\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 3.9806 - mean_absolute_error: 3.9806\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.9537 - mean_absolute_error: 2.9537\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.0507 - mean_absolute_error: 2.0507\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.7650 - mean_absolute_error: 2.7650\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.9313 - mean_absolute_error: 1.9313\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 4.8479 - mean_absolute_error: 4.8479\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.1269 - mean_absolute_error: 2.1269\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.6003 - mean_absolute_error: 1.6003\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.2589 - mean_absolute_error: 2.2589\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.5505 - mean_absolute_error: 2.5505\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.2837 - mean_absolute_error: 3.2837\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.3461 - mean_absolute_error: 3.3461\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.9155 - mean_absolute_error: 2.9155\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.7088 - mean_absolute_error: 2.7088\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.5045 - mean_absolute_error: 2.5045\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.6259 - mean_absolute_error: 1.6259\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.2473 - mean_absolute_error: 1.2473\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.6842 - mean_absolute_error: 2.6842\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.3372 - mean_absolute_error: 1.3372\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.5881 - mean_absolute_error: 1.5881\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.0251 - mean_absolute_error: 2.0251\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 3.4186 - mean_absolute_error: 3.4186\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 3.7955 - mean_absolute_error: 3.7955\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.5194 - mean_absolute_error: 2.5194\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 2.0903 - mean_absolute_error: 2.0903\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 4.0915 - mean_absolute_error: 4.0915\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 3.3028 - mean_absolute_error: 3.3028\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.7987 - mean_absolute_error: 1.7987\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.6949 - mean_absolute_error: 1.6949\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.1021 - mean_absolute_error: 2.1021\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.3723 - mean_absolute_error: 2.3723\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.2481 - mean_absolute_error: 2.2481\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.5012 - mean_absolute_error: 2.5012\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.8656 - mean_absolute_error: 2.8656\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.9151 - mean_absolute_error: 1.9151\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.6849 - mean_absolute_error: 1.6849\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.1670 - mean_absolute_error: 2.1670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c9bf5720>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(1,), activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.mean_absolute_error,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    metrics=['mean_absolute_error']\n",
    ")\n",
    "\n",
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 136ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[20.463522],\n",
       "       [30.684338],\n",
       "       [40.892048]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([10, 20, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "Num GPUs Available:  1\n",
      "WARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x106d9cca0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x106d9cca0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x106d9cca0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x106d9cca0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function normalize_img at 0x106d9cca0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x106d9cca0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/12\n",
      "469/469 [==============================] - 13s 22ms/step - loss: 0.1672 - accuracy: 0.9510 - val_loss: 0.0537 - val_accuracy: 0.9829\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0444 - accuracy: 0.9865 - val_loss: 0.0461 - val_accuracy: 0.9848\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0291 - accuracy: 0.9909 - val_loss: 0.0411 - val_accuracy: 0.9866\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.0396 - val_accuracy: 0.9878\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0358 - val_accuracy: 0.9889\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0445 - val_accuracy: 0.9873\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.0384 - val_accuracy: 0.9890\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0435 - val_accuracy: 0.9879\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0471 - val_accuracy: 0.9877\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0458 - val_accuracy: 0.9893\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.0441 - val_accuracy: 0.9885\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0560 - val_accuracy: 0.9885\n",
      "CPU times: user 1min 43s, sys: 46.8 s, total: 2min 30s\n",
      "Wall time: 1min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cbdd2ec0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#   tf.keras.layers.Dropout(0.25),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=12,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4f407452a8ef3d17fbc767d441d1ca17ac0a8af2a2f0309ff36242fa34224ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
